{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bde.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shenshutao/machine_learning/blob/master/bde.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "78H4AIf8YGHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare environment"
      ]
    },
    {
      "metadata": {
        "id": "buONLccsOl8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!yes | {sys.executable} -m pip uninstall keras\n",
        "!{sys.executable} -m pip install keras==2.1.4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7vUVhD-yPSWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "print keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mtttlh5Or0-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1T6FmeYPhnV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeM_ZXfuWC6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-sG0ymTdTz2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls drive/bde\n",
        "!cp drive/bde/bigdata.zip ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OIB_jKf-Ppxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install unzip\n",
        "!unzip bigdata.zip\n",
        "!mv -f bigdata train_all\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RpZsqATYYX7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define the CNN model"
      ]
    },
    {
      "metadata": {
        "id": "4FFT-Pg0LdHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_input(x):\n",
        "    x /= 255.  # normalization\n",
        "    x -= 0.5  # consider the black padding\n",
        "    x *= 2.\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9C27l2MBhyU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50, Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import backend as K\n",
        "from keras.utils import multi_gpu_model\n",
        "\n",
        "def train_resNet(train_data_dir, validate_data_dir, res_dir, model_file_name, weight_file_name, img_width=224, img_height=224):\n",
        "\n",
        "    if not os.path.exists(res_dir):\n",
        "        os.makedirs(res_dir)\n",
        "\n",
        "    batch_size = 40\n",
        "\n",
        "    # # 2.augmentation (may try more)\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "#         samplewise_std_normalization=True,  # divide each input by its std\n",
        "        # zca_whitening=True,  # apply ZCA whitening\n",
        "        channel_shift_range=100,\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.05,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.05,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        shear_range=0.05,\n",
        "        zoom_range=0.05,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    validate_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        classes=['Beach', 'City', 'Forest', 'Mountain', 'Village'],\n",
        "        class_mode='categorical')\n",
        "\n",
        "    validate_generator = validate_datagen.flow_from_directory(\n",
        "        validate_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        classes=['Beach', 'City', 'Forest', 'Mountain', 'Village'],\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "    \n",
        "    # # 3. model structure\n",
        "    # # Base model Conv layers + Customize FC layers\n",
        "    # # create the base pre-trained model with weights\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        the_input_shape = (3, img_width, img_height)\n",
        "    else:\n",
        "        the_input_shape = (img_width, img_height, 3)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=the_input_shape)  # don't include the top (final FC) layers.\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "    predictions = Dense(5, activation='softmax', name='fc05')(x)\n",
        "\n",
        "    # first: train only the FC layers (which were randomly initialized)\n",
        "    # i.e. freeze all convolutional resnet layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # this is the final model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "#     model = multi_gpu_model(model, gpus=1)\n",
        "#     model.summary()\n",
        "\n",
        "    # # 4.compile the model (should be done *after* setting layers to non-trainable)\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # check model layers\n",
        "#     for i, layer in enumerate(base_model.layers):\n",
        "#        print i, layer.name\n",
        "\n",
        "    # # 5.train the model on the new data for a few epochs\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.n // batch_size,\n",
        "        epochs=2,\n",
        "        validation_data=validate_generator,\n",
        "        validation_steps=validate_generator.n // batch_size)\n",
        "\n",
        "    # model.load_weights('weights_resnet_224_before_finetune.h5')\n",
        "    # # 6.start fine tune.\n",
        "    NB_IV3_LAYERS_TO_FREEZE = 0 # currently 0 freeze layers with low learning rate works best.\n",
        "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # fine tune: stochastic gradient descent optimizer\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # fine tune: train again for fine tune\n",
        "    check_pointer1 = ModelCheckpoint(monitor='val_acc', filepath=os.path.join(res_dir, weight_file_name),\n",
        "                                               verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "    check_pointer2 = ModelCheckpoint(monitor='val_acc', filepath=os.path.join(res_dir, model_file_name),\n",
        "                                               verbose=1, save_best_only=False, save_weights_only=False, mode='auto',\n",
        "                                               period=1)\n",
        "    \n",
        "    tensorboard_callback = TensorBoard(log_dir='/content/logs', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "    model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.n // batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validate_generator,\n",
        "        validation_steps=validate_generator.n // batch_size,\n",
        "        callbacks=[check_pointer1,check_pointer2,tensorboard_callback])\n",
        "\n",
        "    model.save(os.path.join(res_dir, model_file_name))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCB7uowK7d1i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Split data into train / validate set"
      ]
    },
    {
      "metadata": {
        "id": "m8wEpsWnFmfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "def split_data(train_data_dir, test_data_dir, test_precentage):\n",
        "    if not os.path.exists(test_data_dir):\n",
        "        os.makedirs(test_data_dir)\n",
        "\n",
        "    # put all test data back to train data folder\n",
        "    folders = os.listdir(test_data_dir)\n",
        "    for fod in folders:\n",
        "        if not fod.startswith('.'):\n",
        "            files = os.listdir(test_data_dir + '/' + fod)\n",
        "\n",
        "            for f in files:\n",
        "                if not f.startswith('.'):\n",
        "                    shutil.move(test_data_dir + '/' + fod + '/' + f, train_data_dir + '/' + fod + '/' + f)\n",
        "\n",
        "    # redo split train / test\n",
        "    folders = os.listdir(train_data_dir)\n",
        "    for fod in folders:\n",
        "        if not fod.startswith('.'):\n",
        "            files = os.listdir(train_data_dir + '/' + fod)\n",
        "\n",
        "            if not os.path.exists(test_data_dir + '/' + fod):\n",
        "                os.makedirs(test_data_dir + '/' + fod)\n",
        "\n",
        "            for f in files:\n",
        "                if not f.startswith('.'):\n",
        "                    if np.random.rand(1) < test_precentage:\n",
        "                        shutil.move(train_data_dir + '/' + fod + '/' + f, test_data_dir + '/' + fod + '/' + f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDcz_EEdFe4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "split_data('train_all', 'validate_all', 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UT4i-BjoUNIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Start a tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "PGrUlzj8XlNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JE-a8UAN-jDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HjV8buapTjK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/content/logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! export PYTHONIOENCODING=utf8\n",
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0r1wNVV7mZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train Model !"
      ]
    },
    {
      "metadata": {
        "id": "yU6DbxjkEU5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        },
        "outputId": "14b3d143-26c2-4b6b-d1d5-a312ad0d1e0f"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "print keras.__version__\n",
        "\n",
        "# For big image.\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "train_resNet('train_all', 'validate_all', 'resNet', 'resnet_final.h5', 'tmp_weights_resnet_final.h5', 224, 224)\n",
        "\n",
        "# Store the model into google drive\n",
        "!cp -rf resNet drive/bde"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.4\n",
            "Found 1332 images belonging to 5 classes.\n",
            "Found 312 images belonging to 5 classes.\n",
            "Epoch 1/2\n",
            "33/33 [==============================] - 68s 2s/step - loss: 0.9205 - acc: 0.6750 - val_loss: 2.0267 - val_acc: 0.2500\n",
            "Epoch 2/2\n",
            "33/33 [==============================] - 51s 2s/step - loss: 0.4963 - acc: 0.8341 - val_loss: 1.9592 - val_acc: 0.2941\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 73s 2s/step - loss: 0.2728 - acc: 0.8965 - val_loss: 0.2165 - val_acc: 0.9286\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.92857, saving model to resNet/tmp_weights_resnet_final.h5\n",
            "\n",
            "Epoch 00001: saving model to resNet/resnet_final.h5\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 61s 2s/step - loss: 0.0882 - acc: 0.9742 - val_loss: 0.1650 - val_acc: 0.9743\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.92857 to 0.97426, saving model to resNet/tmp_weights_resnet_final.h5\n",
            "\n",
            "Epoch 00002: saving model to resNet/resnet_final.h5\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 60s 2s/step - loss: 0.0421 - acc: 0.9848 - val_loss: 0.0975 - val_acc: 0.9743\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.97426 to 0.97426, saving model to resNet/tmp_weights_resnet_final.h5\n",
            "\n",
            "Epoch 00003: saving model to resNet/resnet_final.h5\n",
            "Epoch 4/50\n",
            " 2/33 [>.............................] - ETA: 38s - loss: 0.0261 - acc: 0.9875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 59s 2s/step - loss: 0.0343 - acc: 0.9924 - val_loss: 0.2191 - val_acc: 0.9375\n",
            "\n",
            "Epoch 00004: val_acc did not improve\n",
            "\n",
            "Epoch 00004: saving model to resNet/resnet_final.h5\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 59s 2s/step - loss: 0.0292 - acc: 0.9917 - val_loss: 0.1322 - val_acc: 0.9743\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.97426 to 0.97426, saving model to resNet/tmp_weights_resnet_final.h5\n",
            "\n",
            "Epoch 00005: saving model to resNet/resnet_final.h5\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 56s 2s/step - loss: 0.0249 - acc: 0.9939 - val_loss: 0.1475 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00006: val_acc did not improve\n",
            "\n",
            "Epoch 00006: saving model to resNet/resnet_final.h5\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 59s 2s/step - loss: 0.0269 - acc: 0.9917 - val_loss: 0.1326 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00007: val_acc did not improve\n",
            "\n",
            "Epoch 00007: saving model to resNet/resnet_final.h5\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 56s 2s/step - loss: 0.0179 - acc: 0.9962 - val_loss: 0.0705 - val_acc: 0.9926\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.97426 to 0.99265, saving model to resNet/tmp_weights_resnet_final.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00008: saving model to resNet/resnet_final.h5\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 58s 2s/step - loss: 0.0189 - acc: 0.9924 - val_loss: 0.1318 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00009: val_acc did not improve\n",
            "\n",
            "Epoch 00009: saving model to resNet/resnet_final.h5\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 59s 2s/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0278 - val_acc: 0.9853\n",
            "\n",
            "Epoch 00010: val_acc did not improve\n",
            "\n",
            "Epoch 00010: saving model to resNet/resnet_final.h5\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 59s 2s/step - loss: 0.0288 - acc: 0.9917 - val_loss: 0.2100 - val_acc: 0.9743\n",
            "\n",
            "Epoch 00011: val_acc did not improve\n",
            "\n",
            "Epoch 00011: saving model to resNet/resnet_final.h5\n",
            "Epoch 12/50\n",
            "32/33 [============================>.] - ETA: 1s - loss: 0.0298 - acc: 0.9930"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AkqHxpln9TEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DyuCEje7tUW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Do prediction"
      ]
    },
    {
      "metadata": {
        "id": "1C88siQBI4SC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls drive/bde\n",
        "!cp drive/bde/pictures.zip .\n",
        "\n",
        "!apt install unzip\n",
        "!unzip pictures.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUiRK-Fg8kMU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "image.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def do_predict(model_h5, weights_h5, img_width, img_height, input_folder, output_file):\n",
        "    model = load_model(model_h5)\n",
        "    if weights_h5 is not None:\n",
        "        model.load_weights(weights_h5)\n",
        "\n",
        "    rows = []\n",
        "    column_names = ['id', 'category']\n",
        "    for f in os.listdir(input_folder):\n",
        "        if not f.startswith('.'):\n",
        "            try:\n",
        "              img = image.load_img(input_folder + '/' + f, target_size=(img_width, img_height))\n",
        "              img_array = image.img_to_array(img)\n",
        "              x = np.expand_dims(img_array, axis=0)\n",
        "              x = preprocess_input(x)\n",
        "              y_prob = model.predict(x)\n",
        "              y_classes = y_prob.argmax(axis=-1)\n",
        "\n",
        "              row = [str(f), str(y_classes[0])]\n",
        "              rows.append(row)\n",
        "            except Exception as e:\n",
        "              print 'Canot predict image: ' + f\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=column_names)\n",
        "    df.to_csv(output_file, index=False, header=True)\n",
        "    print 'Done'\n",
        "    \n",
        "do_predict('resNet/resnet_final.h5', 'resNet/tmp_weights_resnet_final.h5', 224, 224, 'pictures', 'resNet/output_result.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7k1Qxp2LOoxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reformat output accordingly"
      ]
    },
    {
      "metadata": {
        "id": "jBb6SCjBOpkV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('resNet/output_result.csv')\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ftYNHZUPtic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat = {\n",
        "       0: 'Beach', \n",
        "       1: 'City',\n",
        "       2: 'Forest',\n",
        "       3: 'Mountain',\n",
        "       4: 'Village'\n",
        "      }\n",
        "\n",
        "df['city'] = df['id'].apply(lambda jpgname: jpgname.split('_')[1])\n",
        "df['type'] = df['category'].apply(lambda c: cat.get(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsurQpsNSDtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aggdata = df.groupby(['city', 'type']).agg({'type':['count']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "79FNFsMiVOM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pecentData = aggdata / aggdata.groupby(level=0).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRYqqVi3YXQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "column_names = ['Destination', 'Mountain', 'Beach', 'Forest', 'City', 'Village']\n",
        "for city in pecentData.index.levels[0]:  \n",
        "  row = [city,0,0,0,0,0]\n",
        "  rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=column_names)\n",
        "df = df.set_index('Destination')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljP-V3L2eYHu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for index, row in pecentData.iterrows():\n",
        "  df.loc[index[0],index[1]] = str(row[0])\n",
        "  \n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMZNCFwhXmqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv('geofile_shutao.csv', index=True, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-SWs_7wX1dM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -rf geofile_shutao.csv drive/bde\n",
        "!ls drive/bde"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X9NSN7oWSkSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}